{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7J6Z/zIezuXkJvXxlfhc3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"g8ZbnoSlf_FM"},"outputs":[],"source":[]},{"cell_type":"code","source":["Text cell <9rNQk0qAjAuQ>\n","# %% [markdown]\n","# **Clasificación de imágenes (CIFAR-10 data-set)**\n","En este Jupyter Notebook mostraremos cómo clasificar un dat-set de 60,000 imágenes para su correcta clasificación. Nos encontramos ante un claro ejemplo de clasificación, para lo cual haremos uso de una red profunda convolucional que terminará en una capa de salida densa fully-connected del tamaño del número de etiquetas del que consta nuestro data-set.\n","\n","Text cell <BGgyxqNJjGz1>\n","# %% [markdown]\n","##Importar Líbrerias\n","\n","Code cell <M8oehRd9Up0y>\n","# %% [code]\n","import os\n","#import time\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n","from keras.models import Sequential\n","from keras.utils import to_categorical\n","from keras.models import load_model\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","import matplotlib.pyplot as plt\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","Text cell <wN0JptxhjLIT>\n","# %% [markdown]\n","##Cargar conjunto de datos\n","1. El data-set que vamos a usar ocupa aproximadamente 170 MB y se descargará automáticamente desde los tutoriales de ejemplo de Keras.\n","2. En el CIFAR-10 data-set contamos con imágenes de 10 clases distintas: aviones, coches, pájaros, perros, gatos, cérvidos, ranas, equinos, barcos y camiones.\n","\n","- [tensorflow datasets](https://www.tensorflow.org/datasets/catalog/cifar10?hl=es-419)\n","\n","Code cell <67jQ01WsU0r8>\n","# %% [code]\n","from keras.datasets import cifar10\n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","\n","Code cell <oRVgoNRCU6rl>\n","# %% [code]\n","num_train, img_rows, img_cols,  img_channels =  train_images.shape\n","num_train , img_rows, img_cols,  img_channels\n","Execution output\n","0KB\n","\ttext/plain\n","\t\t(50000, 32, 32, 3)\n","\n","Code cell <_njEPhHvVvGs>\n","# %% [code]\n","num_test, _, _, _ =  test_images.shape\n","num_test, img_channels, img_rows, img_cols\n","Execution output\n","0KB\n","\ttext/plain\n","\t\t(10000, 3, 32, 32)\n","\n","Code cell <OL6TR_LBV2HD>\n","# %% [code]\n","class_names = ['airplane','automobile','bird','cat','deer', 'dog','frog','horse','ship','truck']\n","\n","Text cell <S_mNUjkgjPfj>\n","# %% [markdown]\n","##Mostrar imagenes del conjunto de datos\n","\n","\n","\n","Code cell <DdmXd6PQV40k>\n","# %% [code]\n","fig = plt.figure(figsize=(8,3))\n","for i in range(len(class_names)):\n","    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n","    idx = np.where(train_labels == i)[0]\n","    features_idx = train_images[idx]\n","    img_num = np.random.randint(features_idx.shape[0])\n","    im = features_idx[img_num]\n","    ax.set_title(class_names[i])\n","    plt.imshow(im)\n","plt.show()\n","Execution output\n","68KB\n","\ttext/plain\n","\t\t<Figure size 800x300 with 10 Axes>\n","\n","Code cell <JIN5loL9V-AO>\n","# %% [code]\n","# Normalizamos el train y el test data-set entre 0 y 1\n","train_features = train_images.astype('float32') / 255.\n","test_features = test_images.astype('float32') / 255.\n","\n","# Convertimos las etiquetas a variables One-Hot Encoded\n","\n","num_classes = len(np.unique(train_labels))\n","\n","train_labels = to_categorical(train_labels, num_classes)\n","test_labels = to_categorical(test_labels, num_classes)\n","\n","Code cell <NLM5JwJfiaZs>\n","# %% [code]\n","train_labels\n","Execution output\n","0KB\n","\ttext/plain\n","\t\tarray([[0., 0., 0., ..., 0., 0., 0.],\n","\t\t       [0., 0., 0., ..., 0., 0., 1.],\n","\t\t       [0., 0., 0., ..., 0., 0., 1.],\n","\t\t       ...,\n","\t\t       [0., 0., 0., ..., 0., 0., 1.],\n","\t\t       [0., 1., 0., ..., 0., 0., 0.],\n","\t\t       [0., 1., 0., ..., 0., 0., 0.]])\n","\n","Text cell <BZ9NwuUxjW68>\n","# %% [markdown]\n","##Creación del modelo convolucional\n","\n","Code cell <9U0-bFTGXGXp>\n","# %% [code]\n","train_features.shape[1:]\n","Execution output\n","0KB\n","\ttext/plain\n","\t\t(32, 32, 3)\n","\n","Code cell <RALEr6PoWPrS>\n","# %% [code]\n","# Definición del modelo\n","# Iniciamos el modelo de manera secuencial\n","model = Sequential()\n","# Continuamos añadiendo al modelo las capas sin preocuparnos de la dimensionalidad de los inputs\n","# salvo en la primera capa\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu',\n","                 input_shape=train_features.shape[1:]))\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(rate=0.25))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n","\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(rate=0.25))\n","# Hacemos un flattening de la última capa de Pooling\n","model.add(Flatten())\n","\n","model.add(Dense(units=512, activation = 'relu'))\n","\n","model.add(Dropout(rate=0.25))\n","\n","model.add(Dense(units=num_classes, activation='softmax'))\n","\n","Code cell <j0xj5EQEW-3a>\n","# %% [code]\n","# Compilación del modelo\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","Code cell <AP8s0snbW_9y>\n","# %% [code]\n","model.fit(train_features, train_labels, epochs=5)\n","Execution output\n","1KB\n","\tStream\n","\t\tEpoch 1/5\n","\t\t\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 158ms/step - accuracy: 0.6290 - loss: 1.0431\n","\t\tEpoch 2/5\n","\t\t\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 153ms/step - accuracy: 0.6917 - loss: 0.8703\n","\t\tEpoch 3/5\n","\t\t\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 153ms/step - accuracy: 0.7285 - loss: 0.7662\n","\t\tEpoch 4/5\n","\t\t\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 153ms/step - accuracy: 0.7574 - loss: 0.6915\n","\t\tEpoch 5/5\n","\t\t\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 157ms/step - accuracy: 0.7787 - loss: 0.6252\n","\ttext/plain\n","\t\t<keras.src.callbacks.history.History at 0x7c7bf5a73cd0>\n","\n","Text cell <cZoiU91Yjf8L>\n","# %% [markdown]\n","##Guardar el modelo entrenado\n","\n","Code cell <aQq5X0D8Y4jk>\n","# %% [code]\n","model.save('cifar10_model.keras')\n","\n","Code cell <ZaGSXlKEY80v>\n","# %% [code]\n","from keras.models import load_model\n","loaded_model = load_model('cifar10_model.keras')\n","\n","Code cell <jRJNlMY8eGbX>\n","# %% [code]\n","loaded_model.summary()\n","Execution output\n","13KB\n","\ttext/plain\n","\t\t\u001b[1mModel: \"sequential_1\"\u001b[0m\n","\t\t┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","\t\t┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","\t\t┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","\t\t│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,180,160\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","\t\t├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","\t\t│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n","\t\t└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","\t\t\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,752,576\u001b[0m (14.31 MB)\n","\t\t\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,250,858\u001b[0m (4.77 MB)\n","\t\t\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","\t\t\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,501,718\u001b[0m (9.54 MB)\n","\n","Code cell <5ym5P2XIeMYQ>\n","# %% [code]\n","loaded_model.evaluate(test_features, test_labels)\n","predictions = loaded_model.predict(test_features)\n","#predict_classes = loaded_model.predict_classes(test_features)\n","\n","predictions\n","Execution output\n","1KB\n","\tStream\n","\t\t\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.7613 - loss: 0.6799\n","\t\t\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step\n","\ttext/plain\n","\t\tarray([[5.6695886e-04, 5.1733651e-03, 5.9399419e-03, ..., 1.9263122e-03,\n","\t\t        7.4487287e-03, 6.1846193e-04],\n","\t\t       [3.5947275e-03, 3.8610199e-01, 3.1432359e-07, ..., 7.6983468e-09,\n","\t\t        6.1005324e-01, 2.4854043e-04],\n","\t\t       [2.0710558e-01, 1.5387499e-02, 5.3393519e-03, ..., 1.3818155e-03,\n","\t\t        7.3431253e-01, 6.8748472e-03],\n","\t\t       ...,\n","\t\t       [1.8609488e-07, 5.1474082e-08, 7.5205165e-04, ..., 6.8672784e-03,\n","\t\t        9.9046417e-07, 4.7796470e-07],\n","\t\t       [3.8697187e-02, 8.5950333e-01, 2.4262439e-03, ..., 1.4157434e-03,\n","\t\t        3.9290273e-04, 1.7558312e-03],\n","\t\t       [4.9073540e-12, 2.1309521e-13, 2.6166305e-09, ..., 9.9949735e-01,\n","\t\t        5.3883758e-13, 2.9143623e-12]], dtype=float32)\n","\n","Code cell <xIIzerxPetUp>\n","# %% [code]\n","y_test = np.argmax(test_labels, axis=1)\n","y_pred = np.argmax(predictions, axis=1)\n","\n","\n","\n","Code cell <3dZb1BRQiHZA>\n","# %% [code]\n","print(predictions[0])\n","clase = np.argmax(predictions[0])\n","clase\n","\n","Text cell <gIlS_USfiLZN>\n","# %% [markdown]\n","##Metricas\n","\n","Code cell <HZfgBS2xhbNE>\n","# %% [code]\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","# Asume que 'y_true' son las etiquetas verdaderas y 'y_pred' son las etiquetas predichas\n","cm = confusion_matrix(y_test, y_pred)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm) # Reemplaza con tus etiquetas de clase\n","disp.plot()\n","plt.show()\n","Execution output\n","65KB\n","\ttext/plain\n","\t\t<Figure size 640x480 with 2 Axes>\n","\n","Code cell <Mx_AosCnh6FQ>\n","# %% [code]\n","from sklearn.metrics import classification_report\n","\n","# Asume que 'y_true' son las etiquetas verdaderas y 'y_pred' son las etiquetas predichas\n","report = classification_report(y_test, y_pred)\n","\n","print(report)\n","Execution output\n","1KB\n","\tStream\n","\t\tprecision    recall  f1-score   support\n","\n","\t\t           0       0.76      0.81      0.79      1000\n","\t\t           1       0.90      0.86      0.88      1000\n","\t\t           2       0.78      0.55      0.64      1000\n","\t\t           3       0.61      0.52      0.56      1000\n","\t\t           4       0.73      0.74      0.74      1000\n","\t\t           5       0.56      0.79      0.66      1000\n","\t\t           6       0.76      0.86      0.81      1000\n","\t\t           7       0.83      0.79      0.81      1000\n","\t\t           8       0.89      0.85      0.87      1000\n","\t\t           9       0.87      0.84      0.85      1000\n","\n","\t\t    accuracy                           0.76     10000\n","\t\t   macro avg       0.77      0.76      0.76     10000\n","\t\tweighted avg       0.77      0.76      0.76     10000\n","\n","Text cell <KVtUzVwuiVB7>\n","# %% [markdown]\n","##Predicción\n","\n","Code cell <-jowsEyreweh>\n","# %% [code]\n","import cv2\n","from google.colab.patches import cv2_imshow\n","\n","def predecir(path, label):\n","  #Cargar imagen\n","  image = cv2.imread(path)\n","\n","  #Redimensionar 32*32\n","  imagen_redimensionada = cv2.resize(image, (32, 32))\n","\n","  #Mostrar imagen\n","  cv2_imshow(imagen_redimensionada)\n","\n","  #Predecir la clase\n","  clase = np.argmax(loaded_model.predict(np.array([imagen_redimensionada])))\n","  predicted_label = class_names[clase]\n","\n","  print(f\"Etiqueta original: {label}\")\n","  print(f\"Etiqueta predicha: {predicted_label}\")\n","\n","\n","Code cell <4joyHkY1eMiQ>\n","# %% [code]\n","rutas = [[\"/content/airplane_1.webp\",\"airplane\"],\n","         [\"/content/airplane_2.jpg\",\"airplane\"],\n","         [\"/content/bird_1.jpg\",\"bird\"],\n","         [\"/content/bird_2.jpg\",\"bird\"],\n","         [\"/content/cat_1.jpg\",\"cat\"],\n","         [\"/content/cat_2.jpg\",\"cat\"]\n","]\n","\n","for x in rutas:\n","  predecir(x[0], x[1])\n","Execution output\n","27KB\n","\tStream\n","\t\t\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\t\tEtiqueta original: airplane\n","\t\tEtiqueta predicha: airplane\n","\t\t\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\t\tEtiqueta original: airplane\n","\t\tEtiqueta predicha: airplane\n","\t\t\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","\t\tEtiqueta original: bird\n","\t\tEtiqueta predicha: horse\n","\t\t\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\t\tEtiqueta original: bird\n","\t\tEtiqueta predicha: airplane\n","\t\t\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\t\tEtiqueta original: cat\n","\t\tEtiqueta predicha: horse\n","\t\t\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\t\tEtiqueta original: cat\n","\t\tEtiqueta predicha: horse\n","\ttext/plain\n","\t\t<PIL.Image.Image image mode=RGB size=32x32>\n","\t\t<PIL.Image.Image image mode=RGB size=32x32>\n","\t\t<PIL.Image.Image image mode=RGB size=32x32>\n","\t\t<PIL.Image.Image image mode=RGB size=32x32>\n","\t\t<PIL.Image.Image image mode=RGB size=32x32>\n","\t\t<PIL.Image.Image image mode=RGB size=32x32>\n","\n","Text cell <YF55DA1Aku-z>\n","# %% [markdown]\n","Tarea\n","\n","- Crear una red convolucional con el dataset MNIST\n","- Guardar el modelo con .save\n","- Hacer Prdicciones con imagenes\n","- Realizar metricas de evaluación\n","\n","Code cell <by6tIBKak8hp>\n","# %% [code]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"8G7fdohNgCIM","executionInfo":{"status":"error","timestamp":1730410520790,"user_tz":300,"elapsed":210,"user":{"displayName":"Elis Bayona","userId":"08313237383330055775"}},"outputId":"51116be7-f533-46e1-a7d5-51327375ac6e"},"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid decimal literal (<ipython-input-1-1f8ef7cc939c>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-1f8ef7cc939c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Text cell <9rNQk0qAjAuQ>\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"]}]}]}
